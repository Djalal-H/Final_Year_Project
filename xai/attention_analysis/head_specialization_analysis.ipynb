{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Head Specialization Analysis\n",
        "\n",
        "This notebook analyzes attention head behavior to discover **functional specialization** during training.\n",
        "\n",
        "**Goal**: Determine what each attention head has learned to focus on by correlating attention patterns with semantic driving features.\n",
        "\n",
        "## Key Outputs\n",
        "1. **HSI Scores** - Head Specialization Index for each head\n",
        "2. **Functional Labels** - Human-readable labels (Safety Head, Lane Head, etc.)\n",
        "3. **Visualizations** - Heatmaps, scatter plots, evolution charts\n",
        "4. **Head Function Registry** - JSON file for real-time XAI explanations\n",
        "\n",
        "## Data Sources\n",
        "This analysis requires data from **two directories**:\n",
        "1. **Feature Dir** (`runs/{model}/attention_logs/`): Training logs with semantic features from `AttentionLogger`\n",
        "2. **Attention Dir** (`xai/attention_analysis/attention_extractions/`): Offline extracted attention weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - Update these paths for your setup\n",
        "# ============================================================================\n",
        "\n",
        "# Path to training logs (semantic features + metadata)\n",
        "# These are generated by AttentionLogger during training\n",
        "FEATURE_DIR = \"../../runs/PPO_VEC_WAYFORMER/attention_logs/\"  # UPDATE THIS\n",
        "\n",
        "# Path to offline extracted attention weights\n",
        "# These are generated by offline_attention_extraction.ipynb\n",
        "ATTENTION_DIR = \"./attention_extractions/\"  # UPDATE THIS\n",
        "\n",
        "# Output directory for results\n",
        "OUTPUT_DIR = \"./hsi_results/\"\n",
        "\n",
        "# Optional: Filter logs by training step range\n",
        "STEP_RANGE = None  # Or set to (start, end) e.g., (10000, 50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import our analysis module\n",
        "from head_specialization_analysis import (\n",
        "    AttentionLogLoader,\n",
        "    HeadSpecializationAnalyzer,\n",
        "    HeadVisualization,\n",
        "    FEATURE_TO_LABEL\n",
        ")\n",
        "\n",
        "# Set up matplotlib\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"✓ Setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Attention Logs\n",
        "\n",
        "The loader will merge:\n",
        "- **Semantic features** from training logs (TTC, distance, spatial relationships)\n",
        "- **Attention weights** from offline extractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create analyzer with both directories\n",
        "analyzer = HeadSpecializationAnalyzer(\n",
        "    feature_dir=FEATURE_DIR,\n",
        "    attention_dir=ATTENTION_DIR\n",
        ")\n",
        "\n",
        "# Load and merge data\n",
        "analyzer.load_data(step_range=STEP_RANGE)\n",
        "\n",
        "print(f\"\\nLoaded {len(analyzer.logs)} attention logs\")\n",
        "if analyzer.logs:\n",
        "    print(f\"Step range: {analyzer.logs[0].step} → {analyzer.logs[-1].step}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect first log structure\n",
        "if analyzer.logs:\n",
        "    sample_log = analyzer.logs[0]\n",
        "    \n",
        "    print(\"=\" * 50)\n",
        "    print(\"ATTENTION LOG STRUCTURE\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"\\nStep: {sample_log.step}\")\n",
        "    \n",
        "    print(\"\\nAttention weight keys:\")\n",
        "    for key, val in sample_log.attention_weights.items():\n",
        "        print(f\"  {key}: shape={val.shape}\")\n",
        "    \n",
        "    print(\"\\nSemantic features:\")\n",
        "    for key, val in sample_log.semantic_features.items():\n",
        "        if isinstance(val, np.ndarray):\n",
        "            print(f\"  {key}: shape={val.shape}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {val}\")\n",
        "    \n",
        "    print(\"\\nToken boundaries:\")\n",
        "    for key, val in sample_log.token_boundaries.items():\n",
        "        print(f\"  {key}: {val}\")\n",
        "    \n",
        "    print(\"\\nConfig:\")\n",
        "    for key, val in sample_log.config.items():\n",
        "        print(f\"  {key}: {val}\")\n",
        "else:\n",
        "    print(\"⚠ No logs loaded. Check FEATURE_DIR and ATTENTION_DIR paths.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Aggregate Attention by Vehicle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate attention weights by vehicle\n",
        "attention_per_vehicle = analyzer.aggregate_attention_by_vehicle()\n",
        "\n",
        "print(f\"\\nAggregated attention shape: {attention_per_vehicle.shape}\")\n",
        "print(f\"  (N_scenarios, N_heads, N_vehicles)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize attention distribution per head\n",
        "n_heads = attention_per_vehicle.shape[1]\n",
        "\n",
        "fig, axes = plt.subplots(1, n_heads, figsize=(4*n_heads, 4))\n",
        "if n_heads == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for h, ax in enumerate(axes):\n",
        "    head_attn = attention_per_vehicle[:, h, :].flatten()\n",
        "    ax.hist(head_attn, bins=50, alpha=0.7, edgecolor='black')\n",
        "    ax.set_xlabel('Attention Weight')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title(f'Head {h}')\n",
        "    ax.axvline(head_attn.mean(), color='r', linestyle='--', label=f'Mean={head_attn.mean():.3f}')\n",
        "    ax.legend(fontsize=8)\n",
        "\n",
        "plt.suptitle('Attention Weight Distribution per Head', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Aggregate Semantic Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate semantic features\n",
        "features = analyzer.aggregate_features()\n",
        "\n",
        "if features:\n",
        "    print(\"\\nAggregated feature shapes:\")\n",
        "    for name, arr in features.items():\n",
        "        print(f\"  {name}: {arr.shape}\")\n",
        "else:\n",
        "    print(\"⚠ No semantic features found in logs.\")\n",
        "    print(\"  HSI analysis requires training logs (from AttentionLogger).\")\n",
        "    print(\"  Make sure FEATURE_DIR points to runs/{model}/attention_logs/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compute Head Specialization Index (HSI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute HSI\n",
        "try:\n",
        "    result = analyzer.compute_hsi()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"HSI RESULTS SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    for h in range(len(result.hsi_scores)):\n",
        "        label = result.head_labels[h]\n",
        "        print(f\"\\nHead {h}:\")\n",
        "        print(f\"  Name: {label['name']}\")\n",
        "        print(f\"  HSI Score: {label['hsi']:.3f}\")\n",
        "        print(f\"  Primary Feature: {label.get('primary_feature', 'N/A')}\")\n",
        "        print(f\"  Correlation: {label.get('correlation', 0):.3f}\")\n",
        "        print(f\"  Description: {label['description']}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"⚠ Could not compute HSI: {e}\")\n",
        "    print(\"  This typically means semantic features are not available.\")\n",
        "    result = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizer\n",
        "if result is not None:\n",
        "    viz = HeadVisualization(analyzer)\n",
        "    print(\"✓ Visualizer ready\")\n",
        "else:\n",
        "    viz = None\n",
        "    print(\"⚠ Cannot create visualizations without HSI results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if viz is not None:\n",
        "    viz.plot_correlation_heatmap()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 HSI Bar Chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if viz is not None:\n",
        "    viz.plot_hsi_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 Attention vs. Feature Scatter Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if viz is not None and result is not None:\n",
        "    # Plot scatter for each specialized head\n",
        "    for h, label in result.head_labels.items():\n",
        "        if label.get('primary_feature') and label['hsi'] >= 0.3:\n",
        "            print(f\"\\n--- Head {h}: {label['name']} ---\")\n",
        "            viz.plot_attention_vs_feature(h, label['primary_feature'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Export Head Function Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "if result is not None:\n",
        "    registry_path = os.path.join(OUTPUT_DIR, 'head_functions.json')\n",
        "    analyzer.export_registry(registry_path)\n",
        "    \n",
        "    # Display the registry\n",
        "    with open(registry_path, 'r') as f:\n",
        "        registry = json.load(f)\n",
        "    \n",
        "    print(\"\\nHEAD FUNCTION REGISTRY\")\n",
        "    print(\"=\" * 50)\n",
        "    print(json.dumps(registry, indent=2))\n",
        "else:\n",
        "    print(\"⚠ Cannot export registry without HSI results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save All Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if viz is not None:\n",
        "    viz.plot_all(OUTPUT_DIR)\n",
        "    print(f\"\\n✓ All visualizations saved to {OUTPUT_DIR}\")\n",
        "else:\n",
        "    print(\"⚠ Cannot save visualizations without results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Interpretation Guide\n",
        "\n",
        "### What the Results Mean\n",
        "\n",
        "| HSI Score | Interpretation |\n",
        "|-----------|----------------|\n",
        "| > 0.7 | **Strong specialization** - Head clearly focuses on specific feature |\n",
        "| 0.5 - 0.7 | **Moderate specialization** - Head shows preference for certain features |\n",
        "| 0.3 - 0.5 | **Weak specialization** - Slight tendency toward specific features |\n",
        "| < 0.3 | **General context** - Diffuse attention, no clear specialization |\n",
        "\n",
        "### Expected Head Functions\n",
        "\n",
        "| Function | Feature | Expected Correlation | Interpretation |\n",
        "|----------|---------|---------------------|----------------|\n",
        "| **Safety Head** | TTC | Negative | Attends to low-TTC (collision threats) |\n",
        "| **Proximity Head** | Distance | Negative | Attends to nearby vehicles |\n",
        "| **Threat Assessment** | Closing Speed | Positive | Attends to approaching vehicles |\n",
        "| **Traffic Flow** | Is Ahead | Positive | Attends to leading vehicles |\n",
        "| **Lane Awareness** | Is Left/Right | Positive | Monitors adjacent lanes |\n",
        "\n",
        "### Using the Registry for XAI\n",
        "\n",
        "```python\n",
        "# Load registry at inference time\n",
        "with open('head_functions.json') as f:\n",
        "    HEAD_REGISTRY = json.load(f)\n",
        "\n",
        "# Interpret attention during inference\n",
        "def explain_action(attention_weights):\n",
        "    for head_idx, weight in enumerate(attention_weights):\n",
        "        info = HEAD_REGISTRY[str(head_idx)]\n",
        "        if weight > threshold:\n",
        "            print(f\"{info['name']} active: {info['description']}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nData Sources:\")\n",
        "print(f\"  Feature Dir: {FEATURE_DIR}\")\n",
        "print(f\"  Attention Dir: {ATTENTION_DIR}\")\n",
        "print(f\"\\nLogs analyzed: {len(analyzer.logs)}\")\n",
        "print(f\"Scenarios processed: {attention_per_vehicle.shape[0]}\")\n",
        "print(f\"Attention heads: {attention_per_vehicle.shape[1]}\")\n",
        "\n",
        "if result is not None:\n",
        "    specialized = sum(1 for h in result.hsi_scores if h >= 0.3)\n",
        "    strongly_specialized = sum(1 for h in result.hsi_scores if h >= 0.5)\n",
        "    \n",
        "    print(f\"\\nSpecialized heads (HSI ≥ 0.3): {specialized}\")\n",
        "    print(f\"Strongly specialized (HSI ≥ 0.5): {strongly_specialized}\")\n",
        "    \n",
        "    print(f\"\\nOutput files:\")\n",
        "    print(f\"  Registry: {os.path.join(OUTPUT_DIR, 'head_functions.json')}\")\n",
        "    print(f\"  Heatmap: {os.path.join(OUTPUT_DIR, 'correlation_heatmap.png')}\")\n",
        "    print(f\"  HSI Chart: {os.path.join(OUTPUT_DIR, 'hsi_scores.png')}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"✓ Head Specialization Analysis Complete\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "VMax Environment",
      "language": "python",
      "name": "vmax"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
