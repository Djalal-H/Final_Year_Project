{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Head Specialization Analysis - Complete Workflow\n",
        "\n",
        "This notebook demonstrates the complete workflow for analyzing attention head specialization:\n",
        "1. Extract attention weights + semantic features from checkpoints\n",
        "2. Compute Head Specialization Index (HSI)\n",
        "3. Visualize results and interpret head functions\n",
        "\n",
        "**Prerequisites:**\n",
        "- Trained PPO model with Wayformer encoder\n",
        "- Dataset for scenario sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add project root to path\n",
        "project_root = os.path.abspath(\"../..\")\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "from xai.attention_analysis.head_specialization_analysis import HeadSpecializationAnalyzer\n",
        "\n",
        "print(\"‚úì Setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "RUN_DIR = \"../../runs/PPO_VEC_WAYFORMER\"  # Your training run directory\n",
        "DATASET_PATH = \"../../training.tfrecord\"  # Dataset for scenario sampling\n",
        "EXTRACTION_DIR = \"./extractions\"  # Where to save/load extraction results\n",
        "ANALYSIS_DIR = \"./hsi_results\"  # Where to save analysis results\n",
        "\n",
        "# Parameters\n",
        "N_SCENARIOS = 100  # Number of scenarios to analyze\n",
        "CHECKPOINTS = [\"model_final.pkl\"]  # Can add multiple: [\"model_10000.pkl\", \"model_50000.pkl\", ...]\n",
        "\n",
        "os.makedirs(EXTRACTION_DIR, exist_ok=True)\n",
        "os.makedirs(ANALYSIS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Run directory: {RUN_DIR}\")\n",
        "print(f\"Dataset: {DATASET_PATH}\")\n",
        "print(f\"Analyzing {len(CHECKPOINTS)} checkpoint(s) with {N_SCENARIOS} scenarios each\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 1: Extract Attention + Semantic Features\n",
        "\n",
        "Run `offline_extraction.py` to extract both attention weights and semantic features from scenarios.\n",
        "\n",
        "This step:\n",
        "- Loads the trained model checkpoint\n",
        "- Samples scenarios from the dataset  \n",
        "- Extracts attention weights from the Wayformer encoder\n",
        "- Computes semantic features (TTC, distance, closing speed, etc.)\n",
        "- Aggregates attention per vehicle per head\n",
        "- Saves everything to a unified `.pkl` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Run via command line (recommended for large extractions)\n",
        "# Uncomment and run in terminal:\n",
        "\n",
        "cmd = f\"\"\"python offline_extraction.py \\\\\n",
        "    --run_dir {RUN_DIR} \\\\\n",
        "    --dataset {DATASET_PATH} \\\\\n",
        "    --n_scenarios {N_SCENARIOS} \\\\\n",
        "    --output_dir {EXTRACTION_DIR} \\\\\n",
        "    --checkpoints {' '.join(CHECKPOINTS)}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Run this command in terminal:\")\n",
        "print(cmd)\n",
        "print(\"\\nOr uncomment the next cell to run from notebook...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 2: Run from notebook (may be slower, but shows progress)\n",
        "# !cd ../../ && python xai/attention_analysis/offline_extraction.py \\\n",
        "#     --run_dir {RUN_DIR} \\\n",
        "#     --dataset {DATASET_PATH} \\\n",
        "#     --n_scenarios {N_SCENARIOS} \\\n",
        "#     --output_dir xai/attention_analysis/{EXTRACTION_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect Extraction Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Find extraction files\n",
        "extraction_files = sorted(glob.glob(os.path.join(EXTRACTION_DIR, \"extraction_*.pkl\")))\n",
        "\n",
        "if not extraction_files:\n",
        "    print(\"‚ö† No extraction files found. Please run Step 1 first.\")\n",
        "else:\n",
        "    print(f\"Found {len(extraction_files)} extraction file(s):\")\n",
        "    for f in extraction_files:\n",
        "        size_mb = os.path.getsize(f) / 1024 / 1024\n",
        "        print(f\"  - {os.path.basename(f)} ({size_mb:.2f} MB)\")\n",
        "    \n",
        "    # Load and inspect the first one\n",
        "    with open(extraction_files[0], 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    \n",
        "    print(f\"\\nüìä Extraction Summary:\")\n",
        "    print(f\"  Checkpoint: {data['checkpoint']}\")\n",
        "    print(f\"  Training Step: {data['step']}\")\n",
        "    print(f\"  Number of Scenarios: {data['n_scenarios']}\")\n",
        "    \n",
        "    # Inspect first scenario\n",
        "    scenario = data['scenarios'][0]\n",
        "    print(f\"\\nüìã Per-Scenario Data:\")\n",
        "    print(f\"  Attention per vehicle shape: {scenario['attention_per_vehicle'].shape}\")\n",
        "    print(f\"  Semantic features: {list(scenario['semantic_features'].keys())}\")\n",
        "    \n",
        "    # Show sample feature values\n",
        "    print(f\"\\nüìà Example Features (Scenario 0):\")\n",
        "    for key in ['distance_to_ego', 'ttc', 'closing_speed']:\n",
        "        if key in scenario['semantic_features']:\n",
        "            vals = scenario['semantic_features'][key]\n",
        "            print(f\"  {key}: {vals[:3]}... (shape: {vals.shape})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 2: Compute Head Specialization Index (HSI)\n",
        "\n",
        "The HSI analysis computes correlations between each attention head and semantic features:\n",
        "- For each head $h$ and feature $f$: $\\rho_{h,f} = \\text{corr}(\\text{attention}_h, f)$\n",
        "- HSI Score: $\\text{HSI}_h = \\max_f |\\rho_{h,f}|$\n",
        "- Primary Function: The feature with the strongest correlation\n",
        "\n",
        "Heads with high HSI (>0.3) are considered \"specialized\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create analyzer\n",
        "analyzer = HeadSpecializationAnalyzer(extraction_dir=EXTRACTION_DIR)\n",
        "\n",
        "# Load extraction data\n",
        "analyzer.load_data()  # Loads first .pkl file by default\n",
        "\n",
        "# Compute HSI\n",
        "results = analyzer.compute_hsi()\n",
        "\n",
        "print(\"\\n‚úì HSI computation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"HEAD SPECIALIZATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for head_idx, label in results.head_labels.items():\n",
        "    specialized = \"‚úì\" if label['hsi'] >= analyzer.HSI_THRESHOLD else \"‚úó\"\n",
        "    print(f\"\\n{specialized} Head {head_idx}: {label['name']}\")\n",
        "    print(f\"   HSI Score: {label['hsi']:.3f}\")\n",
        "    if label.get('primary_feature'):\n",
        "        print(f\"   Primary Feature: {label['primary_feature']}\")\n",
        "        print(f\"   Correlation: {label['correlation']:.3f} ({label['correlation_sign']})\")\n",
        "        print(f\"   Description: {label['description']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 3: Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Correlation Heatmap\n",
        "\n",
        "Shows correlations between all heads and all semantic features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xai.attention_analysis.head_specialization_analysis import HeadVisualization\n",
        "\n",
        "viz = HeadVisualization(analyzer)\n",
        "\n",
        "# Generate heatmap\n",
        "fig = viz.plot_correlation_heatmap()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 HSI Bar Chart\n",
        "\n",
        "Shows specialization scores for each head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = viz.plot_hsi_bar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Scatter Plots for Specialized Heads\n",
        "\n",
        "For each specialized head, plot attention vs. its primary feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for head_idx, label in results.head_labels.items():\n",
        "    if label.get('primary_feature'):\n",
        "        print(f\"\\nüìä Head {head_idx}: {label['name']}\")\n",
        "        fig = viz.plot_attention_vs_feature(\n",
        "            head_idx=head_idx,\n",
        "            feature_name=label['primary_feature']\n",
        "        )\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 4: Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export head registry to JSON\n",
        "registry_path = os.path.join(ANALYSIS_DIR, \"head_registry.json\")\n",
        "analyzer.export_registry(registry_path)\n",
        "\n",
        "# Save all visualizations\n",
        "viz_dir = os.path.join(ANALYSIS_DIR, \"visualizations\")\n",
        "analyzer.visualize_all(viz_dir)\n",
        "\n",
        "print(f\"\\n‚úì Results saved to: {ANALYSIS_DIR}\")\n",
        "print(f\"  - Registry: {registry_path}\")\n",
        "print(f\"  - Visualizations: {viz_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 5: Evolution Analysis (Optional)\n",
        "\n",
        "If you extracted multiple checkpoints, analyze how head specialization evolves during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(extraction_files) > 1:\n",
        "    print(\"üìà Evolution Analysis\\n\")\n",
        "    \n",
        "    evolution_data = []\n",
        "    \n",
        "    for extraction_file in extraction_files:\n",
        "        # Create fresh analyzer for each checkpoint\n",
        "        analyzer_tmp = HeadSpecializationAnalyzer(extraction_dir=EXTRACTION_DIR)\n",
        "        analyzer_tmp.load_data(extraction_file=os.path.basename(extraction_file))\n",
        "        result = analyzer_tmp.compute_hsi()\n",
        "        \n",
        "        evolution_data.append({\n",
        "            'step': result.checkpoint_step,\n",
        "            'hsi_scores': result.hsi_scores,\n",
        "            'primary_features': result.primary_features\n",
        "        })\n",
        "    \n",
        "    # Plot HSI evolution\n",
        "    n_heads = len(evolution_data[0]['hsi_scores'])\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    for h in range(n_heads):\n",
        "        steps = [d['step'] for d in evolution_data]\n",
        "        hsi_values = [d['hsi_scores'][h] for d in evolution_data]\n",
        "        ax.plot(steps, hsi_values, marker='o', label=f'Head {h}')\n",
        "    \n",
        "    ax.axhline(y=0.3, color='red', linestyle='--', label='Specialization Threshold')\n",
        "    ax.set_xlabel('Training Step')\n",
        "    ax.set_ylabel('HSI Score')\n",
        "    ax.set_title('Head Specialization Evolution During Training')\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n‚úì Evolution analysis complete!\")\n",
        "else:\n",
        "    print(\"‚Ñπ Only one checkpoint found. Extract multiple checkpoints to see evolution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Interpretation Guide\n",
        "\n",
        "### Understanding HSI Scores\n",
        "\n",
        "**HSI (Head Specialization Index)** measures how strongly a head correlates with semantic features:\n",
        "- **HSI > 0.5**: Strong specialization (head has a clear function)\n",
        "- **0.3 < HSI < 0.5**: Moderate specialization\n",
        "- **HSI < 0.3**: General attention (no clear specialization)\n",
        "\n",
        "### Common Head Functions\n",
        "\n",
        "1. **Safety Head** (correlates with TTC)\n",
        "   - Focuses on vehicles with low time-to-collision\n",
        "   - Critical for collision avoidance\n",
        "   \n",
        "2. **Proximity Head** (correlates with distance)\n",
        "   - Attends to nearby vehicles\n",
        "   - Important for lane changing and merging\n",
        "   \n",
        "3. **Traffic Flow Head** (correlates with is_ahead)\n",
        "   - Monitors vehicles ahead in the driving direction\n",
        "   - Essential for speed regulation\n",
        "   \n",
        "4. **Lane Monitoring Heads** (correlates with is_left/is_right)\n",
        "   - Tracks specific lane zones\n",
        "   - Useful for lane-keeping and blind spot awareness\n",
        "\n",
        "### What to Look For\n",
        "\n",
        "‚úÖ **Healthy Model**:\n",
        "- Multiple specialized heads (HSI > 0.3)\n",
        "- At least one Safety Head (TTC correlation)\n",
        "- Diverse primary features across heads\n",
        "\n",
        "‚ö†Ô∏è **Potential Issues**:\n",
        "- All heads are general (HSI < 0.3) ‚Üí Model may be under-trained\n",
        "- No Safety Head ‚Üí Model might not be safety-conscious\n",
        "- All heads have same primary feature ‚Üí Redundant attention\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **If specialization is weak**: Train longer or adjust network architecture\n",
        "2. **If missing critical functions**: Adjust reward function or training scenarios\n",
        "3. **For evolution analysis**: Compare early vs. late training to see when specialization emerges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "1. ‚úÖ Extracting unified attention + semantic data\n",
        "2. ‚úÖ Computing Head Specialization Index (HSI)\n",
        "3. ‚úÖ Visualizing head functions\n",
        "4. ‚úÖ Interpreting results\n",
        "5. ‚úÖ (Optional) Analyzing evolution across checkpoints\n",
        "\n",
        "**Files Generated:**\n",
        "- `extractions/extraction_*.pkl`: Raw extraction data\n",
        "- `hsi_results/head_registry.json`: Head function labels\n",
        "- `hsi_results/visualizations/`: All plots\n",
        "\n",
        "For more details, see:\n",
        "- `offline_extraction.py`: Extraction implementation\n",
        "- `head_specialization_analysis.py`: HSI computation and visualization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
