{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "# Offline Attention Extraction<br>\n", "<br>\n", "This notebook loads a trained model and extracts attention weights from the Wayformer encoder<br>\n", "by running inference on scenarios from the dataset.<br>\n", "<br>\n", "**Workflow:**<br>\n", "1. Load trained model checkpoint<br>\n", "2. Load scenarios from dataset<br>\n", "3. Run forward pass with `return_attention_weights=True`<br>\n", "4. Save/analyze the extracted attention weights"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "Setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import sys\n", "import pickle\n", "import glob\n", "import yaml\n", "import jax\n", "import jax.numpy as jnp\n", "import numpy as np\n", "from functools import partial"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add project root to path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from waymax import dynamics\n", "from vmax.simulator import make_env_for_evaluation, datasets, make_data_generator\n", "from vmax.agents.learning.reinforcement.ppo import ppo_factory\n", "from vmax.scripts.evaluate.utils import load_params, load_yaml_config"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\u2713 Libraries loaded\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "## 1. Configuration<br>\n", "Set paths to your trained model and dataset."]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "=== CONFIGURE THESE ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["RUN_DIR = \"runs/PPO_VEC_WAYFORMER_your_run_name/\"  # Path to training run\n", "DATASET_PATH = \"training\"  # Dataset name or path\n", "NUM_SCENARIOS = 10  # Number of scenarios to process\n", "OUTPUT_DIR = \"attention_extractions/\"  # Where to save results"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Derived paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MODEL_DIR = os.path.join(RUN_DIR, \"model\")\n", "CONFIG_PATH = os.path.join(RUN_DIR, \".hydra/config.yaml\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Run directory: {RUN_DIR}\")\n", "print(f\"Config path: {CONFIG_PATH}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "## 2. Load Model & Environment"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def setup_model_and_env(config_path, model_dir, model_name=\"model_final.pkl\"):\n", "    \"\"\"Load trained model and create matching environment.\"\"\"\n", "    \n", "    # Load config\n", "    config = load_yaml_config(config_path)\n", "    config[\"encoder\"] = config[\"network\"][\"encoder\"]\n", "    \n", "    # Create environment\n", "    term_keys = config.get(\"termination_keys\", [\"offroad\", \"overlap\"])\n", "    env = make_env_for_evaluation(\n", "        max_num_objects=config[\"max_num_objects\"],\n", "        dynamics_model=dynamics.InvertibleBicycleModel(normalize_actions=True),\n", "        sdc_paths_from_data=not config.get(\"waymo_dataset\", False),\n", "        observation_type=config[\"observation_type\"],\n", "        observation_config=config[\"observation_config\"],\n", "        termination_keys=term_keys,\n", "    )\n", "    \n", "    # Build network\n", "    obs_size = env.observation_spec()\n", "    action_size = env.action_spec().data.shape[0]\n", "    unflatten_fn = env.get_wrapper_attr(\"features_extractor\").unflatten_features\n", "    \n", "    networks = ppo_factory.make_networks(\n", "        observation_size=obs_size,\n", "        action_size=action_size,\n", "        unflatten_fn=unflatten_fn,\n", "        learning_rate=3e-4,  # Dummy, not used for inference\n", "        network_config=config\n", "    )\n", "    \n", "    # Load parameters\n", "    model_files = sorted(glob.glob(os.path.join(model_dir, \"*.pkl\")))\n", "    if \"model_final.pkl\" in [os.path.basename(f) for f in model_files]:\n", "        model_path = os.path.join(model_dir, \"model_final.pkl\")\n", "    else:\n", "        model_path = model_files[-1] if model_files else None\n", "    \n", "    if not model_path:\n", "        raise FileNotFoundError(f\"No model found in {model_dir}\")\n", "    \n", "    print(f\"Loading model: {model_path}\")\n", "    params = load_params(model_path)\n", "    \n", "    return env, networks, params, config"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load everything"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if os.path.exists(CONFIG_PATH):\n", "    env, networks, params, config = setup_model_and_env(CONFIG_PATH, MODEL_DIR)\n", "    print(\"\u2713 Model and environment loaded\")\n", "else:\n", "    print(f\"\u26a0 Config not found at {CONFIG_PATH}\")\n", "    print(\"  Please update RUN_DIR to point to your training run.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "## 3. Attention Extraction Function"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_attention_from_scenario(env, networks, params, scenario, rng_key):\n", "    \"\"\"\n", "    Run a single scenario through the model and extract attention weights.\n", "    \n", "    Returns:\n", "        dict with 'observations', 'attention_weights', 'actions'\n", "    \"\"\"\n", "    # Reset environment\n", "    rng_key, reset_key = jax.random.split(rng_key)\n", "    reset_key = jax.random.split(reset_key, 1)  # Batch dim\n", "    env_state = env.reset(scenario, reset_key)\n", "    \n", "    # Get observation\n", "    obs = env_state.observation\n", "    \n", "    # Get the policy network's encoder\n", "    policy_network = networks.policy_network\n", "    \n", "    # We need to call the encoder with return_attention_weights=True\n", "    # The encoder is nested inside the policy network\n", "    # Structure: policy_network.encoder is WayformerEncoder\n", "    \n", "    # Extract encoder params (structure depends on Flax module hierarchy)\n", "    # Usually: params.policy['params']['encoder'] or similar\n", "    \n", "    def forward_with_attention(params, obs):\n", "        \"\"\"Forward pass that returns attention weights.\"\"\"\n", "        # Unflatten observation to dict format expected by encoder\n", "        obs_dict = networks.policy_network.unflatten_fn(obs)\n", "        \n", "        # Call encoder directly with attention flag\n", "        encoder = networks.policy_network.encoder\n", "        \n", "        # Get encoder params from full params\n", "        # The exact path depends on your network structure\n", "        # Common patterns:\n", "        #   params.policy['params']['encoder']\n", "        #   params['policy']['encoder']\n", "        \n", "        latent, attention_weights = encoder.apply(\n", "            {'params': params['encoder']},\n", "            obs_dict,\n", "            return_attention_weights=True\n", "        )\n", "        return latent, attention_weights\n", "    \n", "    # JIT compile\n", "    forward_fn = jax.jit(forward_with_attention)\n", "    \n", "    try:\n", "        # Get policy params\n", "        policy_params = params.policy['params']\n", "        latent, attn_weights = forward_fn(policy_params, obs)\n", "        \n", "        return {\n", "            'observation': jax.device_get(obs),\n", "            'latent': jax.device_get(latent),\n", "            'attention_weights': jax.tree_map(lambda x: np.array(jax.device_get(x)), attn_weights),\n", "            'success': True\n", "        }\n", "    except Exception as e:\n", "        print(f\"  Error during forward pass: {e}\")\n", "        # Try alternative param structure\n", "        try:\n", "            policy_params = params.policy\n", "            latent, attn_weights = forward_fn(policy_params, obs)\n", "            return {\n", "                'observation': jax.device_get(obs),\n", "                'latent': jax.device_get(latent),\n", "                'attention_weights': jax.tree_map(lambda x: np.array(jax.device_get(x)), attn_weights),\n", "                'success': True\n", "            }\n", "        except Exception as e2:\n", "            print(f\"  Alternative also failed: {e2}\")\n", "            return {'success': False, 'error': str(e2)}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "## 4. Process Scenarios"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_extraction(env, networks, params, config, dataset_path, num_scenarios, output_dir):\n", "    \"\"\"Process multiple scenarios and save attention weights.\"\"\"\n", "    \n", "    os.makedirs(output_dir, exist_ok=True)\n", "    \n", "    # Create data generator\n", "    data_gen = make_data_generator(\n", "        path=datasets.get_dataset(dataset_path),\n", "        max_num_objects=config[\"max_num_objects\"],\n", "        include_sdc_paths=not config.get(\"waymo_dataset\", False),\n", "        batch_dims=(1,),  # Single scenario at a time\n", "        seed=42,\n", "        repeat=1,\n", "    )\n", "    \n", "    rng_key = jax.random.PRNGKey(0)\n", "    results = []\n", "    \n", "    print(f\"Processing {num_scenarios} scenarios...\")\n", "    \n", "    for i, scenario in enumerate(data_gen):\n", "        if i >= num_scenarios:\n", "            break\n", "            \n", "        print(f\"  Scenario {i+1}/{num_scenarios}\", end=\"\")\n", "        \n", "        # Squeeze batch dim\n", "        scenario = jax.tree_map(lambda x: x.squeeze(0), scenario)\n", "        \n", "        rng_key, extract_key = jax.random.split(rng_key)\n", "        result = extract_attention_from_scenario(env, networks, params, scenario, extract_key)\n", "        \n", "        if result['success']:\n", "            # Save individual result\n", "            save_path = os.path.join(output_dir, f\"attention_scenario_{i:04d}.pkl\")\n", "            with open(save_path, 'wb') as f:\n", "                pickle.dump(result, f)\n", "            print(f\" \u2713 Saved to {save_path}\")\n", "            results.append(result)\n", "        else:\n", "            print(f\" \u2717 Failed\")\n", "    \n", "    print(f\"\\n\u2713 Extracted attention from {len(results)}/{num_scenarios} scenarios\")\n", "    return results"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Run extraction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if 'env' in dir():\n", "    results = run_extraction(env, networks, params, config, DATASET_PATH, NUM_SCENARIOS, OUTPUT_DIR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "## 5. Analyze Attention Weights"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyze_attention(results):\n", "    \"\"\"Basic analysis of extracted attention weights.\"\"\"\n", "    \n", "    if not results:\n", "        print(\"No results to analyze\")\n", "        return\n", "    \n", "    # Get attention keys from first result\n", "    sample = results[0]['attention_weights']\n", "    print(\"Attention weight keys:\")\n", "    for key in sample.keys():\n", "        shape = sample[key].shape\n", "        print(f\"  {key}: {shape}\")\n", "    \n", "    print(\"\\n\" + \"=\"*50)\n", "    print(\"Attention Statistics (averaged over scenarios)\")\n", "    print(\"=\"*50)\n", "    \n", "    for key in sample.keys():\n", "        weights = [r['attention_weights'][key] for r in results]\n", "        stacked = np.stack(weights)\n", "        \n", "        print(f\"\\n{key}:\")\n", "        print(f\"  Shape: {stacked.shape}\")\n", "        print(f\"  Mean:  {stacked.mean():.4f}\")\n", "        print(f\"  Std:   {stacked.std():.4f}\")\n", "        print(f\"  Max:   {stacked.max():.4f}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if 'results' in dir() and results:\n", "    analyze_attention(results)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "## 6. Visualize Attention (Optional)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_attention_heatmap(attention_weights, key, head_idx=0, save_path=None):\n", "    \"\"\"Plot attention heatmap for a specific layer and head.\"\"\"\n", "    \n", "    if key not in attention_weights:\n", "        print(f\"Key '{key}' not found. Available: {list(attention_weights.keys())}\")\n", "        return\n", "    \n", "    attn = attention_weights[key]\n", "    \n", "    # Shape is typically (batch, heads, query, key) or (heads, query, key)\n", "    if attn.ndim == 4:\n", "        attn = attn[0]  # Take first batch\n", "    \n", "    if attn.ndim == 3:\n", "        attn = attn[head_idx]  # Take specific head\n", "    \n", "    plt.figure(figsize=(10, 8))\n", "    plt.imshow(attn, cmap='viridis', aspect='auto')\n", "    plt.colorbar(label='Attention Weight')\n", "    plt.xlabel('Key Position')\n", "    plt.ylabel('Query Position')\n", "    plt.title(f'Attention: {key} (Head {head_idx})')\n", "    \n", "    if save_path:\n", "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n", "        print(f\"Saved to {save_path}\")\n", "    \n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Example: Plot first result's attention"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if 'results' in dir() and results:\n", "    sample_attn = results[0]['attention_weights']\n", "    first_key = list(sample_attn.keys())[0]\n", "    plot_attention_heatmap(sample_attn, first_key)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}